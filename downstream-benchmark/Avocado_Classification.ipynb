{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# File: Avocado_Classification.ipynb\n",
    "# Author: Vraj Shah\n",
    "# Revisions by: Francisco Cornejo-Garcia\n",
    "# Description: Classify date and time\n",
    "# ==============================================================================\n",
    "\n",
    "# Load libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load additional libraries\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "# Load scikit-learn libraries\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "from sklearn.svm import LinearSVC,LinearSVR\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load models\n",
    "from downstream_models import LogRegClassifier, RandForestClassifier, LinearRegression, RandForestRegressor, MLPRegressorr, MLPClassifierr\n",
    "from custom_functions import validate, findSeason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "avocado = pd.read_csv('dataset/avocado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datetime dataframe\n",
    "org_datetime_df = pd.DataFrame()\n",
    "org_datetime_df['datetime'] = avocado['Date']\n",
    "datetime_col = avocado['Date']\n",
    "\n",
    "# Create arrays to be added to dataframe\n",
    "season_arr = []\n",
    "date_arr = []\n",
    "year_arr = []\n",
    "month_arr = []\n",
    "day_arr = []\n",
    "dayofyear_arr = []\n",
    "time_arr = []\n",
    "hour_arr = []\n",
    "minute_arr = []\n",
    "\n",
    "# Extract features from datetime values in column\n",
    "for value in datetime_col:\n",
    "    datetime = validate(value)\n",
    "    date = datetime.date()\n",
    "    time = datetime.time()\n",
    "    \n",
    "    season_arr.append(findSeason(date.month, date.day))\n",
    "    date_arr.append(date)\n",
    "    year_arr.append(date.year)\n",
    "    month_arr.append(date.month)\n",
    "    day_arr.append(date.day)\n",
    "    dayofyear_arr.append(date.timetuple().tm_yday)\n",
    "    time_arr.append(time)\n",
    "    hour_arr.append(time.hour)\n",
    "    minute_arr.append(time.minute)\n",
    "\n",
    "# Combine arrays as dataframes into one dataframe\n",
    "season_df = pd.DataFrame(season_arr)\n",
    "date_df = pd.DataFrame(date_arr)\n",
    "year_df = pd.DataFrame(year_arr)\n",
    "month_df = pd.DataFrame(month_arr)\n",
    "day_df = pd.DataFrame(day_arr)\n",
    "dayofyear_df = pd.DataFrame(dayofyear_arr)\n",
    "time_df = pd.DataFrame(time_arr)\n",
    "hour_df = pd.DataFrame(hour_arr)\n",
    "minute_df = pd.DataFrame(minute_arr)\n",
    "datetime_df = pd.concat([season_df, date_df, year_df, month_df, day_df, dayofyear_df, time_df, hour_df, minute_df], axis = 1, sort = False)\n",
    "datetime_df.columns = ['season', 'date', 'year', 'month', 'day', 'day_of_year', 'time', 'hour', 'minute']\n",
    "datetime_df = datetime_df.fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Benchmark 1\n",
    "# Create separate columns\n",
    "target = avocado['type']\n",
    "numeric_cols = avocado[['AveragePrice', 'Total Volume', '4046', '4225', '4770']]\n",
    "ngram1_cols = avocado[['Date']]\n",
    "\n",
    "# Create ngram vectorizer\n",
    "vectorizer = CountVectorizer(ngram_range = (2,2),analyzer = 'char')\n",
    "\n",
    "# Create dataframe\n",
    "benchmark1_df = pd.DataFrame()\n",
    "benchmark1_df = pd.concat([benchmark1_df, numeric_cols], axis = 1, sort = False)\n",
    "\n",
    "# Iterate through each ngram column\n",
    "for col in ngram1_cols.columns:\n",
    "    array = ngram1_cols[col].astype(str).values\n",
    "    X = vectorizer.fit_transform(array)\n",
    "    vectorizer_df = pd.DataFrame(X.toarray())\n",
    "    benchmark1_df = pd.concat([benchmark1_df, vectorizer_df], axis = 1, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold Train, Validation, and Test Accuracies:\n",
      "[0.7267745526158061, 0.7270314239232811, 0.9247367069098382, 0.9283329052144875, 0.9202054794520548]\n",
      "[0.7273972602739726, 0.7188356164383561, 0.9366438356164384, 0.923972602739726, 0.9277149708804385]\n",
      "[0.7254794520547945, 0.7254794520547945, 0.9224657534246575, 0.9232876712328767, 0.9178082191780822]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.8454162136230936\n",
      "0.8469128571897864\n",
      "0.842904109589041\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Benchmark 1\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst, cnf_matrix = LogRegClassifier(benchmark1_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold Train, Validation, and Test Accuracies:\n",
      "[0.9939207123897594, 0.9945200787738676, 0.9934069697748095, 0.9934069697748095, 0.9940924657534247]\n",
      "[0.9756849315068493, 0.9736301369863014, 0.9811643835616438, 0.977054794520548, 0.9746488523466941]\n",
      "[0.9758904109589042, 0.9767123287671233, 0.9789041095890411, 0.9758904109589042, 0.9789041095890411]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.993869439293334\n",
      "0.9764366197844072\n",
      "0.9772602739726027\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Benchmark 1\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst, cnf_matrix = RandForestClassifier(benchmark1_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold Train, Validation, and Test Accuracies:\n",
      "[0.9194280332220224, 0.9213973799126638, 0.9184861717612809, 0.9214830036818221, 0.9184931506849315]\n",
      "[0.9215753424657535, 0.9136986301369863, 0.9253424657534246, 0.9133561643835616, 0.9253168893456664]\n",
      "[0.9183561643835616, 0.9183561643835616, 0.9183561643835616, 0.9183561643835616, 0.9183561643835616]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.9198575478525441\n",
      "0.9198578984170785\n",
      "0.9183561643835617\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier & Regressor Benchmark 1\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst = MLPClassifierr(benchmark1_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark 2\n",
    "# Create separate columns\n",
    "numeric_cols = avocado[['AveragePrice', 'Total Volume', '4046', '4225', '4770']] + datetime_df[['year', 'day', 'day_of_year', 'hour', 'minute']]\n",
    "ngram2_cols = avocado[['Date']]\n",
    "\n",
    "# Create dataframe\n",
    "benchmark2_df = pd.DataFrame()\n",
    "benchmark2_df = pd.concat([benchmark2_df, numeric_cols], axis = 1, sort = False)\n",
    "\n",
    "# Iterate through each ngram column\n",
    "for col in ngram2_cols.columns:\n",
    "    array = ngram2_cols[col].astype(str).values\n",
    "    X = vectorizer.fit_transform(array)\n",
    "    vectorizer_df = pd.DataFrame(X.toarray())\n",
    "    benchmark2_df = pd.concat([benchmark2_df, vectorizer_df], axis = 1, sort = False)\n",
    "benchmark2_df = benchmark2_df.fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold Train, Validation, and Test Accuracies:\n",
      "[0.5001284356537374, 0.5014984159602706, 0.504837742957445, 0.5088620601078859, 0.5040239726027397]\n",
      "[0.5092465753424658, 0.501027397260274, 0.4948630136986301, 0.47363013698630135, 0.49194929770469337]\n",
      "[0.4917808219178082, 0.49397260273972604, 0.4882191780821918, 0.4928767123287671, 0.4931506849315068]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.5038701254564157\n",
      "0.494143284198473\n",
      "0.492\n"
     ]
    }
   ],
   "source": [
    "# Log Regression Benchmark 2\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst, cnf_matrix = LogRegClassifier(benchmark2_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold Train, Validation, and Test Accuracies:\n",
      "[0.5157975854097098, 0.5068927134172446, 0.5093758027228359, 0.5175956845620344, 0.5068493150684932]\n",
      "[0.45787671232876714, 0.4828767123287671, 0.4794520547945205, 0.4547945205479452, 0.49640287769784175]\n",
      "[0.4832876712328767, 0.4917808219178082, 0.4865753424657534, 0.4797260273972603, 0.48054794520547944]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.5113022202360635\n",
      "0.47428057553956837\n",
      "0.48438356164383556\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier Benchmark 2\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst, cnf_matrix = RandForestClassifier(benchmark2_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold Train, Validation, and Test Accuracies:\n",
      "[0.512372634643377, 0.5184519222536176, 0.5150269714872848, 0.5202500214059423, 0.5166095890410959]\n",
      "[0.5332191780821918, 0.5089041095890411, 0.5226027397260274, 0.5017123287671232, 0.5162726961288112]\n",
      "[0.43397260273972604, 0.43397260273972604, 0.43397260273972604, 0.43397260273972604, 0.43397260273972604]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.5165422277662636\n",
      "0.516542210458639\n",
      "0.43397260273972604\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier Benchmark 2\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst = MLPClassifierr(benchmark2_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark 3\n",
    "# Create separate columns\n",
    "numeric_cols = avocado[['AveragePrice', 'Total Volume', '4046', '4225', '4770']]\n",
    "categ_cols = datetime_df[['year', 'day', 'day_of_year', 'hour', 'minute']]\n",
    "ngram3_cols = avocado[['Date']]\n",
    "\n",
    "# Create dataframe\n",
    "benchmark3_df = pd.DataFrame()\n",
    "benchmark3_df = pd.concat([benchmark3_df, numeric_cols], axis = 1, sort = False)\n",
    "\n",
    "# Create encoder\n",
    "enc = OneHotEncoder(handle_unknown = 'ignore')\n",
    "X = enc.fit_transform(categ_cols)\n",
    "enc_df = pd.DataFrame(X.toarray())\n",
    "benchmark3_df = pd.concat([benchmark3_df, enc_df], axis = 1, sort = False)\n",
    "\n",
    "# Iterate through each ngram column\n",
    "for col in ngram3_cols.columns:\n",
    "    array = ngram3_cols[col].astype(str).values\n",
    "    X = vectorizer.fit_transform(array)\n",
    "    vectorizer_df = pd.DataFrame(X.toarray())\n",
    "    benchmark3_df = pd.concat([benchmark3_df, vectorizer_df], axis = 1, sort = False)\n",
    "benchmark3_df = benchmark3_df.fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold Train, Validation, and Test Accuracies:\n",
      "[0.7267745526158061, 0.7270314239232811, 0.9243942118332049, 0.9289322715985958, 0.9268835616438356]\n",
      "[0.7273972602739726, 0.7188356164383561, 0.936986301369863, 0.9208904109589041, 0.934566632408359]\n",
      "[0.7254794520547945, 0.7254794520547945, 0.9221917808219178, 0.9213698630136986, 0.9213698630136986]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.8468032043229448\n",
      "0.847735244289891\n",
      "0.8431780821917808\n"
     ]
    }
   ],
   "source": [
    "# Log Regression Benchmark 3\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst, cnf_matrix = LogRegClassifier(benchmark3_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold Train, Validation, and Test Accuracies:\n",
      "[0.9928932271598596, 0.992208237006593, 0.9913519993150098, 0.9926363558523846, 0.9924657534246575]\n",
      "[0.9674657534246576, 0.9667808219178082, 0.9746575342465753, 0.9739726027397261, 0.9681397738951696]\n",
      "[0.9679452054794521, 0.9663013698630137, 0.9682191780821918, 0.9679452054794521, 0.9698630136986301]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.9923111145517008\n",
      "0.9702032972447874\n",
      "0.9680547945205479\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier Benchmark 3\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst, cnf_matrix = RandForestClassifier(benchmark3_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold Train, Validation, and Test Accuracies:\n",
      "[0.9440876787396181, 0.9458001541227845, 0.9423752033564518, 0.9463138967377344, 0.9440068493150685]\n",
      "[0.9462328767123288, 0.9393835616438356, 0.9530821917808219, 0.9373287671232877, 0.94655704008222]\n",
      "[0.9394520547945205, 0.9394520547945205, 0.9394520547945205, 0.9394520547945205, 0.9394520547945205]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.9445167564543315\n",
      "0.9445168874684986\n",
      "0.9394520547945205\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier Benchmark 3\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst = MLPClassifierr(benchmark3_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark 4\n",
    "# Create separate columns\n",
    "numeric_cols = avocado[['AveragePrice', 'Total Volume', '4046', '4225', '4770']] + datetime_df[['year', 'day', 'day_of_year', 'hour', 'minute']]\n",
    "categ_cols = datetime_df[['year', 'day', 'day_of_year', 'hour', 'minute']]\n",
    "ngram4_cols = avocado[['Date']]\n",
    "\n",
    "# Create dataframe\n",
    "benchmark4_df = pd.DataFrame()\n",
    "benchmark4_df = pd.concat([benchmark4_df, numeric_cols], axis = 1, sort = False)\n",
    "\n",
    "# Create encoder\n",
    "enc = OneHotEncoder(handle_unknown = 'ignore')\n",
    "X = enc.fit_transform(categ_cols)\n",
    "enc_df = pd.DataFrame(X.toarray())\n",
    "benchmark4_df = pd.concat([benchmark4_df, enc_df], axis = 1, sort = False)\n",
    "\n",
    "# Iterate through each ngram column\n",
    "for col in ngram4_cols.columns:\n",
    "    array = ngram4_cols[col].astype(str).values\n",
    "    X = vectorizer.fit_transform(array)\n",
    "    vectorizer_df = pd.DataFrame(X.toarray())\n",
    "    benchmark4_df = pd.concat([benchmark4_df, vectorizer_df], axis = 1, sort = False)\n",
    "benchmark4_df = benchmark4_df.fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold Train, Validation, and Test Accuracies:\n",
      "[0.5001284356537374, 0.5032108913434369, 0.5056939806490282, 0.511858892028427, 0.5040239726027397]\n",
      "[0.5092465753424658, 0.49726027397260275, 0.49246575342465754, 0.4726027397260274, 0.49194929770469337]\n",
      "[0.4917808219178082, 0.4915068493150685, 0.4873972602739726, 0.4841095890410959, 0.4931506849315068]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.5049832344554739\n",
      "0.4927049280340893\n",
      "0.4895890410958904\n"
     ]
    }
   ],
   "source": [
    "# Log Regression Benchmark 4\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst, cnf_matrix = LogRegClassifier(benchmark4_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold Train, Validation, and Test Accuracies:\n",
      "[0.5078345748779861, 0.5060364757256615, 0.5044096241116534, 0.5162257042555013, 0.5054794520547945]\n",
      "[0.4876712328767123, 0.4863013698630137, 0.5020547945205479, 0.4613013698630137, 0.49023638232271327]\n",
      "[0.4852054794520548, 0.4917808219178082, 0.4846575342465753, 0.4791780821917808, 0.4898630136986301]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.5079971662051193\n",
      "0.4855130298892002\n",
      "0.48613698630136987\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier Benchmark 4\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst, cnf_matrix = RandForestClassifier(benchmark4_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold Train, Validation, and Test Accuracies:\n",
      "[0.5151982190256015, 0.5183662984844593, 0.5163113280246596, 0.5175100607928761, 0.5197773972602739]\n",
      "[0.5263698630136986, 0.5136986301369864, 0.5219178082191781, 0.5171232876712328, 0.5080507022953066]\n",
      "[0.4301369863013699, 0.4301369863013699, 0.4301369863013699, 0.4301369863013699, 0.4301369863013699]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.5174326607175741\n",
      "0.5174320582672804\n",
      "0.4301369863013699\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier Benchmark 4 \n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst = MLPClassifierr(benchmark4_df, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
