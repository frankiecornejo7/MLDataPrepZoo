{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn import metrics\n",
    "import enchant\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "from sklearn.svm import LinearSVC,LinearSVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPClassifier,MLPRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn import tree\n",
    "# from downstream_models import LogRegClassifier, RandForestClassifier, LinearRegression, RandForestRegressor, MLPRegressorr, MLPClassifierr\n",
    "\n",
    "import sys\n",
    "\n",
    "maxintval = sys.maxsize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "Hcurstate = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iot = pd.read_csv('dataset/iot.csv')\n",
    "iot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numeric_cols = iot[['temp']]\n",
    "# categ_cols = iot[['Conditions']]\n",
    "# categ_cols = pd.get_dummies(categ_cols, columns=['Conditions'])\n",
    "ngram_cols = iot[['room_id/id','noted_date']]\n",
    "\n",
    "target = iot['out/in']\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2),analyzer='char')\n",
    "all_cols = pd.DataFrame()\n",
    "all_cols = pd.concat([all_cols,numeric_cols], axis=1, sort=False)\n",
    "\n",
    "for cols in ngram_cols.columns:\n",
    "    print(cols)\n",
    "    arr = ngram_cols[cols].astype(str).values\n",
    "    X = vectorizer.fit_transform(arr)\n",
    "    tempdf = pd.DataFrame(X.toarray())\n",
    "    all_cols = pd.concat([all_cols,tempdf], axis=1, sort=False)\n",
    "\n",
    "all_cols = all_cols.fillna('0')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# avgsc_train_lst,avgsc_lst,avgsc_hld_lst = LinearRegression(all_cols,target)\n",
    "avgsc_train_lst,avgsc_lst,avgsc_hld_lst,cnf_matrix = LogRegClassifier(all_cols,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# avgsc_train_lst,avgsc_lst,avgsc_hld_lst = RandForestRegressor(all_cols,target)\n",
    "avgsc_train_lst,avgsc_lst,avgsc_hld_lst,cnf_matrix = RandForestClassifier(all_cols,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# avgsc_train_lst,avgsc_lst,avgsc_hld_lst = MLPRegressorr(all_cols,target)\n",
    "avgsc_train_lst,avgsc_lst,avgsc_hld_lst,cnf_matrix = MLPClassifierr(all_cols,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def LogRegClassifier(data1,y):\n",
    "\n",
    "    X_train, X_test,y_train,y_test = train_test_split(data1,y, test_size=0.2,random_state=Hcurstate)\n",
    "    X_train_new = X_train.reset_index(drop=True)\n",
    "    y_train_new = y_train.reset_index(drop=True)\n",
    "    \n",
    "    X_train_new = X_train_new.values\n",
    "    y_train_new = y_train_new.values\n",
    "\n",
    "    k = 5\n",
    "    kf = KFold(n_splits=k,random_state=Hcurstate)\n",
    "    avg_train_acc,avg_test_acc = 0,0\n",
    "\n",
    "    val_arr = [0.0001,0.001,0.01,0.1,1,10,100,1000,10000,100000]\n",
    "\n",
    "    avgsc_lst,avgsc_train_lst,avgsc_hld_lst = [],[],[]\n",
    "    avgsc,avgsc_train,avgsc_hld = 0,0,0\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train_new):\n",
    "        X_train_cur, X_test_cur = X_train_new[train_index], X_train_new[test_index]\n",
    "        y_train_cur, y_test_cur = y_train_new[train_index], y_train_new[test_index]\n",
    "        X_train_train, X_val,y_train_train,y_val = train_test_split(X_train_cur,y_train_cur, test_size=0.25,random_state=Hcurstate)\n",
    "\n",
    "        print(X_train_train.shape)\n",
    "        print(X_val.shape)\n",
    "        \n",
    "        bestPerformingModel = LogisticRegression(penalty='l2',C = 1,random_state=Hcurstate)\n",
    "        bestscore = 0\n",
    "        for val in val_arr:\n",
    "            clf = LogisticRegression(penalty='l2',C = val,random_state=Hcurstate)\n",
    "            clf.fit(X_train_train, y_train_train)\n",
    "            sc = clf.score(X_val, y_val)\n",
    "\n",
    "            if bestscore < sc:\n",
    "                bestscore = sc\n",
    "                bestPerformingModel = clf\n",
    "\n",
    "        bscr_train = bestPerformingModel.score(X_train_cur, y_train_cur)\n",
    "        bscr = bestPerformingModel.score(X_test_cur, y_test_cur)\n",
    "        bscr_hld = bestPerformingModel.score(X_test, y_test)\n",
    "\n",
    "        avgsc_train_lst.append(bscr_train)\n",
    "        avgsc_lst.append(bscr)\n",
    "        avgsc_hld_lst.append(bscr_hld)\n",
    "\n",
    "        avgsc_train = avgsc_train + bscr_train    \n",
    "        avgsc = avgsc + bscr\n",
    "        avgsc_hld = avgsc_hld + bscr_hld\n",
    "\n",
    "        print(bscr_train)\n",
    "        print(bscr)\n",
    "        print(bscr_hld)\n",
    "    \n",
    "    print('5 fold Train, Validation, and Test Accuracies:')\n",
    "    print(avgsc_train_lst)\n",
    "    print(avgsc_lst)\n",
    "    print(avgsc_hld_lst)\n",
    "\n",
    "    print('Avg Train, Validation, and Test Accuracies:')    \n",
    "    print(avgsc_train/k)\n",
    "    print(avgsc/k)\n",
    "    print(avgsc_hld/k)\n",
    "        \n",
    "    y_pred = bestPerformingModel.predict(X_test)\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return avgsc_train_lst,avgsc_lst,avgsc_hld_lst,cnf_matrix\n",
    "\n",
    "\n",
    "def RandForestClassifier(data1,y):\n",
    "    X_train, X_test,y_train,y_test = train_test_split(data1,y, test_size=0.2,random_state=Hcurstate)\n",
    "    \n",
    "    X_train_new = X_train.reset_index(drop=True)\n",
    "    y_train_new = y_train.reset_index(drop=True)\n",
    "    \n",
    "    X_train_new = X_train_new.values\n",
    "    y_train_new = y_train_new.values\n",
    "\n",
    "    k = 5\n",
    "    kf = KFold(n_splits=k,random_state=Hcurstate)\n",
    "    avg_train_acc,avg_test_acc = 0,0\n",
    "\n",
    "    n_estimators_grid = [5,25,50,75,100,500]\n",
    "    max_depth_grid = [5,10,25,50,100,500]\n",
    "\n",
    "    avgsc_lst,avgsc_train_lst,avgsc_hld_lst = [],[],[]\n",
    "    avgsc,avgsc_train,avgsc_hld = 0,0,0\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train_new):\n",
    "        X_train_cur, X_test_cur = X_train_new[train_index], X_train_new[test_index]\n",
    "        y_train_cur, y_test_cur = y_train_new[train_index], y_train_new[test_index]\n",
    "        X_train_train, X_val,y_train_train,y_val = train_test_split(X_train_cur,y_train_cur, test_size=0.25,random_state=Hcurstate)\n",
    "\n",
    "        print(X_train_train.shape)\n",
    "        print(X_val.shape)            \n",
    "        \n",
    "        bestPerformingModel = RandomForestClassifier(n_estimators=10,max_depth=5, random_state=Hcurstate)\n",
    "        bestscore = 0\n",
    "        for ne in n_estimators_grid:\n",
    "            for md in max_depth_grid:\n",
    "                clf = RandomForestClassifier(n_estimators=ne,max_depth=md, random_state=Hcurstate)\n",
    "                clf.fit(X_train_train, y_train_train)\n",
    "                sc = clf.score(X_val, y_val)\n",
    "\n",
    "                if bestscore < sc:\n",
    "                    bestscore = sc\n",
    "                    bestPerformingModel = clf\n",
    "\n",
    "        bscr_train = bestPerformingModel.score(X_train_cur, y_train_cur)\n",
    "        bscr = bestPerformingModel.score(X_test_cur, y_test_cur)\n",
    "        bscr_hld = bestPerformingModel.score(X_test, y_test)\n",
    "\n",
    "        avgsc_train_lst.append(bscr_train)\n",
    "        avgsc_lst.append(bscr)\n",
    "        avgsc_hld_lst.append(bscr_hld)\n",
    "\n",
    "        avgsc_train = avgsc_train + bscr_train    \n",
    "        avgsc = avgsc + bscr\n",
    "        avgsc_hld = avgsc_hld + bscr_hld\n",
    "\n",
    "        print(bscr_train)\n",
    "        print(bscr)\n",
    "        print(bscr_hld)\n",
    "    \n",
    "    print('5 fold Train, Validation, and Test Accuracies:')\n",
    "    print(avgsc_train_lst)\n",
    "    print(avgsc_lst)\n",
    "    print(avgsc_hld_lst)\n",
    "    \n",
    "    print('Avg Train, Validation, and Test Accuracies:')    \n",
    "    print(avgsc_train/k)\n",
    "    print(avgsc/k)\n",
    "    print(avgsc_hld/k)\n",
    "        \n",
    "    y_pred = bestPerformingModel.predict(X_test)\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return avgsc_train_lst,avgsc_lst,avgsc_hld_lst,cnf_matrix\n",
    "\n",
    "\n",
    "def LinearRegression(data1,y):\n",
    "\n",
    "    X_train, X_test,y_train,y_test = train_test_split(data1,y, test_size=0.2,random_state=Hcurstate)\n",
    "\n",
    "    X_train_new = X_train.reset_index(drop=True)\n",
    "    y_train_new = y_train.reset_index(drop=True)\n",
    "    \n",
    "    X_train_new = X_train_new.values\n",
    "    y_train_new = y_train_new.values\n",
    "\n",
    "    k = 5\n",
    "    kf = KFold(n_splits=k,random_state=Hcurstate)\n",
    "    avg_train_acc,avg_test_acc = 0,0\n",
    "\n",
    "    val_arr = [0.0001,0.001,0.01,0.1,1,10,100,1000,10000,100000]\n",
    "\n",
    "    avgsc_lst,avgsc_train_lst,avgsc_hld_lst = [],[],[]\n",
    "    avgsc,avgsc_train,avgsc_hld = 0,0,0\n",
    "\n",
    "    i=0\n",
    "    for train_index, test_index in kf.split(X_train_new):\n",
    "#         if i>0: break\n",
    "#         i=i+1\n",
    "        X_train_cur, X_test_cur = X_train_new[train_index], X_train_new[test_index]\n",
    "        y_train_cur, y_test_cur = y_train_new[train_index], y_train_new[test_index]\n",
    "        X_train_train, X_val,y_train_train,y_val = train_test_split(X_train_cur,y_train_cur, test_size=0.25,random_state=Hcurstate)\n",
    "\n",
    "        print(X_train_train.shape)\n",
    "        print(X_val.shape)            \n",
    "        \n",
    "        bestPerformingModel = Ridge(alpha=1.0,random_state=Hcurstate)\n",
    "        bestscore = maxintval\n",
    "\n",
    "        for val in val_arr:\n",
    "            clf = Ridge(alpha=val,random_state=Hcurstate)\n",
    "            clf = clf.fit(X_train_train, y_train_train)\n",
    "            y_pred = clf.predict(X_val)\n",
    "            sc = sqrt(mean_squared_error(y_pred, y_val))\n",
    "#             print(sc)\n",
    "            if bestscore > sc:\n",
    "                bestscore = sc\n",
    "                bestPerformingModel = clf\n",
    "\n",
    "\n",
    "        y_pred = bestPerformingModel.predict(X_train_cur)\n",
    "        bscr_train = sqrt(mean_squared_error(y_pred, y_train_cur))\n",
    "        \n",
    "        y_pred = bestPerformingModel.predict(X_test_cur)\n",
    "        bscr = sqrt(mean_squared_error(y_pred, y_test_cur))\n",
    "        \n",
    "        y_pred = bestPerformingModel.predict(X_test)\n",
    "        bscr_hld = sqrt(mean_squared_error(y_pred, y_test))\n",
    "\n",
    "        avgsc_train_lst.append(bscr_train)\n",
    "        avgsc_lst.append(bscr)\n",
    "        avgsc_hld_lst.append(bscr_hld)\n",
    "\n",
    "        avgsc_train = avgsc_train + bscr_train    \n",
    "        avgsc = avgsc + bscr\n",
    "        avgsc_hld = avgsc_hld + bscr_hld\n",
    "\n",
    "        print(bscr_train)\n",
    "        print(bscr)\n",
    "        print(bscr_hld)\n",
    "    \n",
    "\n",
    "    print('5-fold Train, Validation, and Test loss:')\n",
    "    print(avgsc_train_lst)\n",
    "    print(avgsc_lst)\n",
    "    print(avgsc_hld_lst)\n",
    "    \n",
    "    print('Avg Train, Validation, and Test loss:')    \n",
    "    print(avgsc_train/k)\n",
    "    print(avgsc/k)\n",
    "    print(avgsc_hld/k)\n",
    "    \n",
    "    return avgsc_train_lst,avgsc_lst,avgsc_hld_lst\n",
    "\n",
    "def RandForestRegressor(data1,y):\n",
    "    X_train, X_test,y_train,y_test = train_test_split(data1,y, test_size=0.2,random_state=Hcurstate)\n",
    "\n",
    "    X_train_new = X_train.reset_index(drop=True)\n",
    "    y_train_new = y_train.reset_index(drop=True)\n",
    "    \n",
    "    X_train_new = X_train_new.values\n",
    "    y_train_new = y_train_new.values\n",
    "\n",
    "    k = 5\n",
    "    kf = KFold(n_splits=k,random_state=Hcurstate)\n",
    "    avg_train_acc,avg_test_acc = 0,0\n",
    "\n",
    "    n_estimators_grid = [5,25,50,75,100,500]\n",
    "    max_depth_grid = [5,10,25,50,100,500]\n",
    "\n",
    "    avgsc_lst,avgsc_train_lst,avgsc_hld_lst = [],[],[]\n",
    "    avgsc,avgsc_train,avgsc_hld = 0,0,0\n",
    "\n",
    "    i=0\n",
    "    for train_index, test_index in kf.split(X_train_new):\n",
    "#         if i>0: break\n",
    "#         i=i+1        \n",
    "        X_train_cur, X_test_cur = X_train_new[train_index], X_train_new[test_index]\n",
    "        y_train_cur, y_test_cur = y_train_new[train_index], y_train_new[test_index]\n",
    "        X_train_train, X_val,y_train_train,y_val = train_test_split(X_train_cur,y_train_cur, test_size=0.25,random_state=Hcurstate)\n",
    "\n",
    "        print(X_train_train.shape)\n",
    "        print(X_val.shape)            \n",
    "        \n",
    "        bestPerformingModel = RandomForestRegressor(n_estimators=10,max_depth=5, random_state=Hcurstate)\n",
    "        bestscore = maxintval\n",
    "        for ne in n_estimators_grid:\n",
    "            for md in max_depth_grid:\n",
    "                clf = RandomForestRegressor(n_estimators=ne,max_depth=md, random_state=Hcurstate)\n",
    "                clf = clf.fit(X_train_train, y_train_train)\n",
    "                \n",
    "                y_pred = clf.predict(X_val)\n",
    "                sc = sqrt(mean_squared_error(y_pred, y_val))                \n",
    "                sc = clf.score(X_val, y_val)\n",
    "\n",
    "                if bestscore > sc:\n",
    "                    bestscore = sc\n",
    "                    bestPerformingModel = clf\n",
    "\n",
    "        y_pred = bestPerformingModel.predict(X_train_cur)\n",
    "        bscr_train = sqrt(mean_squared_error(y_pred, y_train_cur))\n",
    "        \n",
    "        y_pred = bestPerformingModel.predict(X_test_cur)\n",
    "        bscr = sqrt(mean_squared_error(y_pred, y_test_cur))\n",
    "        \n",
    "        y_pred = bestPerformingModel.predict(X_test)\n",
    "        bscr_hld = sqrt(mean_squared_error(y_pred, y_test))\n",
    "\n",
    "        avgsc_train_lst.append(bscr_train)\n",
    "        avgsc_lst.append(bscr)\n",
    "        avgsc_hld_lst.append(bscr_hld)\n",
    "\n",
    "        avgsc_train = avgsc_train + bscr_train    \n",
    "        avgsc = avgsc + bscr\n",
    "        avgsc_hld = avgsc_hld + bscr_hld\n",
    "\n",
    "        print(bscr_train)\n",
    "        print(bscr)\n",
    "        print(bscr_hld)\n",
    "    \n",
    "    print('5-fold Train, Validation, and Test loss:')\n",
    "    print(avgsc_train_lst)\n",
    "    print(avgsc_lst)\n",
    "    print(avgsc_hld_lst)\n",
    "    \n",
    "    print('Avg Train, Validation, and Test loss:')    \n",
    "    print(avgsc_train/k)\n",
    "    print(avgsc/k)\n",
    "    print(avgsc_hld/k)\n",
    "\n",
    "    y_pred = bestPerformingModel.predict(X_test)\n",
    "    \n",
    "    return avgsc_train_lst,avgsc_lst,avgsc_hld_lst\n",
    "\n",
    "\n",
    "def MLPRegressorr(data1,y):\n",
    "    \n",
    "    X_train, X_test,y_train,y_test = train_test_split(data1,y, test_size=0.2,random_state=Hcurstate)\n",
    "\n",
    "    X_train_new = X_train.reset_index(drop=True)\n",
    "    y_train_new = y_train.reset_index(drop=True)\n",
    "    \n",
    "    X_train_new = X_train_new.values\n",
    "    y_train_new = y_train_new.values\n",
    "\n",
    "    k = 5\n",
    "    kf = KFold(n_splits=k,random_state=Hcurstate)\n",
    "    avg_train_acc,avg_test_acc = 0,0\n",
    "\n",
    "    n_estimators_grid = [5,25,50,75,100,500]\n",
    "    max_depth_grid = [5,10,25,50,100,500]\n",
    "\n",
    "    avgsc_lst,avgsc_train_lst,avgsc_hld_lst = [],[],[]\n",
    "    avgsc,avgsc_train,avgsc_hld = 0,0,0\n",
    "\n",
    "    i=0\n",
    "    for train_index, test_index in kf.split(X_train_new):\n",
    "#         if i>0: break\n",
    "#         i=i+1        \n",
    "        X_train_cur, X_test_cur = X_train_new[train_index], X_train_new[test_index]\n",
    "        y_train_cur, y_test_cur = y_train_new[train_index], y_train_new[test_index]\n",
    "        X_train_train, X_val,y_train_train,y_val = train_test_split(X_train_cur,y_train_cur, test_size=0.25,random_state=Hcurstate)\n",
    "\n",
    "        print(X_train_train.shape)\n",
    "        print(X_val.shape)            \n",
    "        \n",
    "        bestPerformingModel = MLPRegressor(hidden_layer_sizes=(100, 100), max_iter=300 , random_state=Hcurstate)\n",
    "        bestPerformingModel = bestPerformingModel.fit(X_train, y_train)\n",
    "        print(bestPerformingModel.n_layers_)\n",
    "\n",
    "        y_pred = bestPerformingModel.predict(X_train_cur)\n",
    "        bscr_train = sqrt(mean_squared_error(y_pred, y_train_cur))\n",
    "        \n",
    "        y_pred = bestPerformingModel.predict(X_test_cur)\n",
    "        bscr = sqrt(mean_squared_error(y_pred, y_test_cur))\n",
    "        \n",
    "        y_pred = bestPerformingModel.predict(X_test)\n",
    "        bscr_hld = sqrt(mean_squared_error(y_pred, y_test))\n",
    "\n",
    "        avgsc_train_lst.append(bscr_train)\n",
    "        avgsc_lst.append(bscr)\n",
    "        avgsc_hld_lst.append(bscr_hld)\n",
    "\n",
    "        avgsc_train = avgsc_train + bscr_train    \n",
    "        avgsc = avgsc + bscr\n",
    "        avgsc_hld = avgsc_hld + bscr_hld\n",
    "\n",
    "        print(bscr_train)\n",
    "        print(bscr)\n",
    "        print(bscr_hld)\n",
    "    \n",
    "    print('5-fold Train, Validation, and Test loss:')\n",
    "    print(avgsc_train_lst)\n",
    "    print(avgsc_lst)\n",
    "    print(avgsc_hld_lst)\n",
    "    \n",
    "    print('Avg Train, Validation, and Test loss:')    \n",
    "    print(avgsc_train/k)\n",
    "    print(avgsc/k)\n",
    "    print(avgsc_hld/k)\n",
    "\n",
    "    y_pred = bestPerformingModel.predict(X_test)\n",
    "    \n",
    "    return avgsc_train_lst,avgsc_lst,avgsc_hld_lst\n",
    "\n",
    "\n",
    "def MLPClassifierr(data1,y):\n",
    "    \n",
    "    X_train, X_test,y_train,y_test = train_test_split(data1,y, test_size=0.2,random_state=Hcurstate)\n",
    "\n",
    "    X_train_new = X_train.reset_index(drop=True)\n",
    "    y_train_new = y_train.reset_index(drop=True)\n",
    "    \n",
    "    X_train_new = X_train_new.values\n",
    "    y_train_new = y_train_new.values\n",
    "\n",
    "    k = 5\n",
    "    kf = KFold(n_splits=k,random_state=Hcurstate)\n",
    "    avg_train_acc,avg_test_acc = 0,0\n",
    "\n",
    "    n_estimators_grid = [5,25,50,75,100,500]\n",
    "    max_depth_grid = [5,10,25,50,100,500]\n",
    "\n",
    "    avgsc_lst,avgsc_train_lst,avgsc_hld_lst = [],[],[]\n",
    "    avgsc,avgsc_train,avgsc_hld = 0,0,0\n",
    "\n",
    "    i=0\n",
    "    for train_index, test_index in kf.split(X_train_new):\n",
    "#         if i>0: break\n",
    "#         i=i+1        \n",
    "        X_train_cur, X_test_cur = X_train_new[train_index], X_train_new[test_index]\n",
    "        y_train_cur, y_test_cur = y_train_new[train_index], y_train_new[test_index]\n",
    "        X_train_train, X_val,y_train_train,y_val = train_test_split(X_train_cur,y_train_cur, test_size=0.25,random_state=Hcurstate)\n",
    "\n",
    "        print(X_train_train.shape)\n",
    "        print(X_val.shape)            \n",
    "        \n",
    "        bestPerformingModel = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=300 , random_state=Hcurstate)\n",
    "        bestPerformingModel = bestPerformingModel.fit(X_train, y_train)\n",
    "        \n",
    "        bscr_train = bestPerformingModel.score(X_train_cur, y_train_cur)\n",
    "        bscr = bestPerformingModel.score(X_test_cur, y_test_cur)\n",
    "        bscr_hld = bestPerformingModel.score(X_test, y_test)\n",
    "\n",
    "        avgsc_train_lst.append(bscr_train)\n",
    "        avgsc_lst.append(bscr)\n",
    "        avgsc_hld_lst.append(bscr_hld)\n",
    "\n",
    "        avgsc_train = avgsc_train + bscr_train    \n",
    "        avgsc = avgsc + bscr\n",
    "        avgsc_hld = avgsc_hld + bscr_hld\n",
    "\n",
    "        print(bscr_train)\n",
    "        print(bscr)\n",
    "        print(bscr_hld)\n",
    "    \n",
    "    print('5-fold Train, Validation, and Test Accuracies:')\n",
    "    print(avgsc_train_lst)\n",
    "    print(avgsc_lst)\n",
    "    print(avgsc_hld_lst)\n",
    "    \n",
    "    print('Avg Train, Validation, and Test Accuracies:')    \n",
    "    print(avgsc_train/k)\n",
    "    print(avgsc/k)\n",
    "    print(avgsc_hld/k)\n",
    "\n",
    "    y_pred = bestPerformingModel.predict(X_test)\n",
    "    \n",
    "    return avgsc_train_lst,avgsc_lst,avgsc_hld_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
