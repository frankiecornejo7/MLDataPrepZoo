{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# File: NYC_Temp_Classification.ipynb\n",
    "# Author: Vraj Shah\n",
    "# Revisions by: Francisco Cornejo-Garcia\n",
    "# Description: Classify date and time\n",
    "# ==============================================================================\n",
    "\n",
    "# Load libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load additional libraries\n",
    "from datetime import datetime \n",
    "from dateutil.parser import parse\n",
    "\n",
    "# Load scikit-learn libraries\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "from sklearn.svm import LinearSVC,LinearSVR\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load models\n",
    "from downstream_models import LogRegClassifier, RandForestClassifier, LinearRegression, RandForestRegressor, MLPRegressorr, MLPClassifierr\n",
    "from custom_functions import validate, findSeason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "nyc = pd.read_csv('dataset/nyc.csv')\n",
    "\n",
    "# Convert 'Calm' to '0' for Wind SpeedMPH Column\n",
    "for index, value in enumerate(nyc['Wind SpeedMPH']):\n",
    "    if value == 'Calm':\n",
    "        nyc['Wind SpeedMPH'][index] = '0'\n",
    "\n",
    "# Convert NA to '0'\n",
    "nyc = nyc.fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datetime dataframe\n",
    "org_datetime_df = pd.DataFrame()\n",
    "org_datetime_df['datetime'] = nyc['date'] + ' ' + nyc['TimeEST']\n",
    "datetime_col = nyc['date'] + ' ' + nyc['TimeEST']\n",
    "\n",
    "# Create arrays to be added to dataframe\n",
    "season_arr = []\n",
    "date_arr = []\n",
    "year_arr = []\n",
    "month_arr = []\n",
    "day_arr = []\n",
    "dayofyear_arr = []\n",
    "time_arr = []\n",
    "hour_arr = []\n",
    "minute_arr = []\n",
    "\n",
    "# Extract features from datetime values in column\n",
    "for value in datetime_col:\n",
    "    datetime = validate(value)\n",
    "    date = datetime.date()\n",
    "    time = datetime.time()\n",
    "    \n",
    "    season_arr.append(findSeason(date.month, date.day))\n",
    "    date_arr.append(date)\n",
    "    year_arr.append(date.year)\n",
    "    month_arr.append(date.month)\n",
    "    day_arr.append(date.day)\n",
    "    dayofyear_arr.append(date.timetuple().tm_yday)\n",
    "    time_arr.append(time)\n",
    "    hour_arr.append(time.hour)\n",
    "    minute_arr.append(time.minute)\n",
    "\n",
    "# Combine arrays as dataframes into one dataframe\n",
    "season_df = pd.DataFrame(season_arr)\n",
    "date_df = pd.DataFrame(date_arr)\n",
    "year_df = pd.DataFrame(year_arr)\n",
    "month_df = pd.DataFrame(month_arr)\n",
    "day_df = pd.DataFrame(day_arr)\n",
    "dayofyear_df = pd.DataFrame(dayofyear_arr)\n",
    "time_df = pd.DataFrame(time_arr)\n",
    "hour_df = pd.DataFrame(hour_arr)\n",
    "minute_df = pd.DataFrame(minute_arr)\n",
    "datetime_df = pd.concat([season_df, date_df, year_df, month_df, day_df, dayofyear_df, time_df, hour_df, minute_df], axis = 1, sort = False)\n",
    "datetime_df.columns = ['season', 'date', 'year', 'month', 'day', 'day_of_year', 'time', 'hour', 'minute']\n",
    "datetime_df = datetime_df.fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark 1 Baseline\n",
    "# Create separate columns\n",
    "target = nyc['Conditions']\n",
    "numeric_cols = nyc[['TemperatureF', 'Dew PointF', 'Humidity', 'Wind SpeedMPH']]\n",
    "ngram1_cols = nyc[['date', 'TimeEST']]\n",
    "\n",
    "# Create ngram vectorizer\n",
    "vectorizer = CountVectorizer(ngram_range = (2, 2), analyzer = 'char')\n",
    "\n",
    "# Create dataframe\n",
    "benchmark1_df = pd.DataFrame()\n",
    "benchmark1_df = pd.concat([benchmark1_df, numeric_cols], axis = 1, sort = False)\n",
    "\n",
    "# Apply ngram vectorizer to data\n",
    "for col in ngram1_cols.columns:\n",
    "    array = ngram1_cols[col].astype(str).values\n",
    "    X = vectorizer.fit_transform(array)\n",
    "    vectorizer_df = pd.DataFrame(X.toarray())\n",
    "    benchmark1_df = pd.concat([benchmark1_df, vectorizer_df], axis = 1, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold Train, Validation, and Test Accuracies:\n",
      "[0.5019762845849802, 0.50653694131955, 0.5127659574468085, 0.5130699088145897, 0.5106382978723404]\n",
      "[0.5078979343863913, 0.503037667071689, 0.5097323600973236, 0.5182481751824818, 0.524330900243309]\n",
      "[0.5121477162293488, 0.5238095238095238, 0.5228377065111759, 0.5170068027210885, 0.521865889212828]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.5089974780076537\n",
      "0.5126494073962389\n",
      "0.519533527696793\n"
     ]
    }
   ],
   "source": [
    "# Log Regression Benchmark 1\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst, cnf_matrix = LogRegClassifier(benchmark1_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold Train, Validation, and Test Accuracies:\n",
      "[0.9245971419884463, 0.9276375798114929, 0.9249240121580548, 0.9246200607902736, 0.9194528875379939]\n",
      "[0.6780072904009721, 0.6658566221142163, 0.6715328467153284, 0.6605839416058394, 0.683698296836983]\n",
      "[0.6958211856171039, 0.6997084548104956, 0.6890184645286687, 0.6831875607385811, 0.6861030126336248]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.9242463364572522\n",
      "0.6719357995346679\n",
      "0.6907677356656949\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier Benchmark 1\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst, cnf_matrix = RandForestClassifier(benchmark1_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold Train, Validation, and Test Accuracies:\n",
      "[0.5880206749771967, 0.582547886895713, 0.5863221884498481, 0.5869300911854103, 0.5805471124620061]\n",
      "[0.5722964763061968, 0.5941676792223572, 0.5790754257907542, 0.5766423357664233, 0.6021897810218978]\n",
      "[0.5519922254616132, 0.5519922254616132, 0.5519922254616132, 0.5519922254616132, 0.5519922254616132]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.5848735907940348\n",
      "0.5848743396215259\n",
      "0.5519922254616132\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier Benchmark 1\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst = MLPClassifierr(benchmark1_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark 2 Numerical\n",
    "# Create separate columns\n",
    "numeric_cols = nyc[['TemperatureF', 'Dew PointF', 'Humidity', 'Wind SpeedMPH']] + datetime_df[['year', 'day', 'day_of_year', 'hour', 'minute']]\n",
    "ngram2_cols = nyc[['date', 'TimeEST']]\n",
    "\n",
    "# Create dataframe\n",
    "benchmark2_df = pd.DataFrame()\n",
    "benchmark2_df = pd.concat([benchmark2_df, numeric_cols], axis = 1, sort = False)\n",
    "\n",
    "# Apply ngram vectorizer to data\n",
    "for col in ngram2_cols.columns:\n",
    "    array = ngram2_cols[col].astype(str).values\n",
    "    X = vectorizer.fit_transform(array)\n",
    "    vectorizer_df = pd.DataFrame(X.toarray())\n",
    "    benchmark2_df = pd.concat([benchmark2_df, vectorizer_df], axis = 1, sort = False)\n",
    "benchmark2_df = benchmark2_df.fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold Train, Validation, and Test Accuracies:\n",
      "[0.5408938887199757, 0.541501976284585, 0.5355623100303951, 0.5355623100303951, 0.5583586626139818]\n",
      "[0.5236938031591738, 0.5164034021871203, 0.5279805352798054, 0.5206812652068127, 0.5413625304136253]\n",
      "[0.5451895043731778, 0.5354713313896987, 0.5413022351797862, 0.5374149659863946, 0.5422740524781341]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.5423758295358665\n",
      "0.5260243072493075\n",
      "0.5403304178814383\n"
     ]
    }
   ],
   "source": [
    "# Log Regression Benchmark 2\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst, cnf_matrix = LogRegClassifier(benchmark2_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold Train, Validation, and Test Accuracies:\n",
      "[0.9075706901793859, 0.9148677409546975, 0.9069908814589666, 0.9109422492401216, 0.9072948328267477]\n",
      "[0.606318347509113, 0.6002430133657352, 0.610705596107056, 0.6228710462287105, 0.6277372262773723]\n",
      "[0.6316812439261419, 0.6258503401360545, 0.6209912536443148, 0.6268221574344023, 0.6112730806608357]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.9095332789319837\n",
      "0.6135750458975974\n",
      "0.6233236151603497\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier Benchmark 2\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst, cnf_matrix = RandForestClassifier(benchmark2_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold Train, Validation, and Test Accuracies:\n",
      "[0.9990878686530861, 0.9996959562176954, 0.9990881458966565, 0.9990881458966565, 0.9993920972644377]\n",
      "[1.0, 0.9975698663426489, 1.0, 1.0, 0.9987834549878345]\n",
      "[0.6248785228377065, 0.6248785228377065, 0.6248785228377065, 0.6248785228377065, 0.6248785228377065]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.9992704427857063\n",
      "0.9992706642660967\n",
      "0.6248785228377065\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier Benchmark 2\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst = MLPClassifierr(benchmark2_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark 3 Categorical\n",
    "# Create separate columns\n",
    "numeric_cols = nyc[['TemperatureF', 'Dew PointF', 'Humidity', 'Wind SpeedMPH']]\n",
    "categ_cols = datetime_df[['date', 'year', 'day', 'day_of_year', 'time', 'hour', 'minute']]\n",
    "ngram3_cols = nyc[['date', 'TimeEST']]\n",
    "\n",
    "# Create dataframe\n",
    "benchmark3_df = pd.DataFrame()\n",
    "benchmark3_df = pd.concat([benchmark3_df, numeric_cols], axis = 1, sort = False)\n",
    "\n",
    "# Create encoder\n",
    "enc = OneHotEncoder(handle_unknown = 'ignore')\n",
    "X = enc.fit_transform(categ_cols)\n",
    "enc_df = pd.DataFrame(X.toarray())\n",
    "benchmark3_df = pd.concat([benchmark3_df, enc_df], axis = 1, sort = False)\n",
    "\n",
    "# Apply ngram vectorizer to data\n",
    "for col in ngram3_cols.columns:\n",
    "    array = ngram3_cols[col].astype(str).values\n",
    "    X = vectorizer.fit_transform(array)\n",
    "    vectorizer_df = pd.DataFrame(X.toarray())\n",
    "    benchmark3_df = pd.concat([benchmark3_df, vectorizer_df], axis = 1, sort = False)\n",
    "benchmark3_df = benchmark3_df.fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold Train, Validation, and Test Accuracies:\n",
      "[0.5053207661903314, 0.5138339920948617, 0.5085106382978724, 0.5130699088145897, 0.5072948328267477]\n",
      "[0.5078979343863913, 0.4908869987849332, 0.49148418491484186, 0.5097323600973236, 0.5206812652068127]\n",
      "[0.5238095238095238, 0.5170068027210885, 0.5121477162293488, 0.5199222546161322, 0.5160349854227405]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.5096060276448806\n",
      "0.5041365486780606\n",
      "0.5177842565597668\n"
     ]
    }
   ],
   "source": [
    "# Log Regression Benchmark 3\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst, cnf_matrix = LogRegClassifier(benchmark3_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold Train, Validation, and Test Accuracies:\n",
      "[0.924901185770751, 0.9297658862876255, 0.9261398176291793, 0.9249240121580548, 0.9191489361702128]\n",
      "[0.6901579586877278, 0.6597812879708383, 0.683698296836983, 0.6751824817518248, 0.6909975669099757]\n",
      "[0.6967930029154519, 0.6997084548104956, 0.6831875607385811, 0.6880466472303207, 0.6890184645286687]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.9249759676031648\n",
      "0.67996351843147\n",
      "0.6913508260447037\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier Benchmark 3\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst, cnf_matrix = RandForestClassifier(benchmark3_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold Train, Validation, and Test Accuracies:\n",
      "[0.8771663119489207, 0.8738218303435695, 0.8732522796352583, 0.8765957446808511, 0.8741641337386018]\n",
      "[0.8663426488456865, 0.8797083839611178, 0.8819951338199513, 0.8686131386861314, 0.878345498783455]\n",
      "[0.6676384839650146, 0.6676384839650146, 0.6676384839650146, 0.6676384839650146, 0.6676384839650146]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.8750000600694403\n",
      "0.8750009608192684\n",
      "0.6676384839650146\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier Benchmark 3\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst = MLPClassifierr(benchmark3_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark 4 Categorical\n",
    "# Create separate columns\n",
    "numeric_cols = nyc[['TemperatureF', 'Dew PointF', 'Humidity', 'Wind SpeedMPH']] + datetime_df[['year', 'day', 'day_of_year', 'hour', 'minute']]\n",
    "categ_cols = datetime_df[['date', 'year', 'day', 'day_of_year', 'time', 'hour', 'minute']]\n",
    "ngram4_cols = nyc[['date', 'TimeEST']]\n",
    "\n",
    "# Create dataframe\n",
    "benchmark4_df = pd.DataFrame()\n",
    "benchmark4_df = pd.concat([benchmark4_df, numeric_cols], axis = 1, sort = False)\n",
    "\n",
    "# Create encoder\n",
    "enc = OneHotEncoder(handle_unknown = 'ignore')\n",
    "X = enc.fit_transform(categ_cols)\n",
    "enc_df = pd.DataFrame(X.toarray())\n",
    "benchmark4_df = pd.concat([benchmark4_df, enc_df], axis = 1, sort = False)\n",
    "\n",
    "# Apply ngram vectorizer to data\n",
    "for col in ngram4_cols.columns:\n",
    "    array = ngram4_cols[col].astype(str).values\n",
    "    X = vectorizer.fit_transform(array)\n",
    "    vectorizer_df = pd.DataFrame(X.toarray())\n",
    "    benchmark4_df = pd.concat([benchmark4_df, vectorizer_df], axis = 1, sort = False)\n",
    "benchmark4_df = benchmark4_df.fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Log Regression Benchmark 4\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst, cnf_matrix = LogRegClassifier(benchmark4_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random Forest Classifier Benchmark 4\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst, cnf_matrix = RandForestClassifier(benchmark4_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MLP Classifier Benchmark 4\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst = MLPClassifierr(benchmark4_df, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
