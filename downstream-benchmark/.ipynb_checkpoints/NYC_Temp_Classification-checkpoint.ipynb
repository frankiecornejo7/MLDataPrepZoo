{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# File: NYC_Temp_Classification.ipynb\n",
    "# Author: Vraj Shah\n",
    "# Revisions by: Francisco Cornejo-Garcia\n",
    "# Description: Classify date and time\n",
    "# ==============================================================================\n",
    "\n",
    "# Load models\n",
    "from downstream_models import LogRegClassifier, RandForestClassifier, LinearRegression, RandForestRegressor, MLPRegressorr, MLPClassifierr\n",
    "\n",
    "# Load libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load scikit-learn libraries\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "from sklearn.svm import LinearSVC,LinearSVR\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "nyc = pd.read_csv('dataset/nyc.csv')\n",
    "# Rename columns\n",
    "nyc.columns = ['date', 'est_time', 'tempF', 'dewpointF', 'humidity', 'windspeedmph', 'conditions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate columns\n",
    "numeric_cols = nyc[['tempF']]\n",
    "ngram_cols = nyc[['date', 'est_time']]\n",
    "target = nyc['conditions']\n",
    "\n",
    "# Create ngram vectorizer\n",
    "vectorizer = CountVectorizer(ngram_range = (2,2),analyzer = 'char')\n",
    "\n",
    "# Create dataframe\n",
    "table = pd.DataFrame()\n",
    "table = pd.concat([table, numeric_cols], axis = 1, sort = False)\n",
    "\n",
    "# Iterate through each ngram column\n",
    "for col in ngram_cols.columns:\n",
    "    # Transform values in column as strings\n",
    "    array = ngram_cols[col].astype(str).values\n",
    "    X = vectorizer.fit_transform(array)\n",
    "    dataframe = pd.DataFrame(X.toarray())\n",
    "    table = pd.concat([table, dataframe], axis = 1, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2466, 133)\n",
      "(823, 133)\n",
      "0.5010641532380663\n",
      "0.4896719319562576\n",
      "0.5043731778425656\n",
      "(2466, 133)\n",
      "(823, 133)\n",
      "0.492550927333536\n",
      "0.47023086269744835\n",
      "0.48882410106899904\n",
      "(2467, 133)\n",
      "(823, 133)\n",
      "0.5306990881458966\n",
      "0.51338199513382\n",
      "0.5286686103012633\n",
      "(2467, 133)\n",
      "(823, 133)\n",
      "0.506079027355623\n",
      "0.4975669099756691\n",
      "0.5092322643343051\n",
      "(2467, 133)\n",
      "(823, 133)\n",
      "0.4987841945288754\n",
      "0.5121654501216545\n",
      "0.5063168124392614\n",
      "5 fold Train, Validation, and Test Accuracies:\n",
      "[0.5010641532380663, 0.492550927333536, 0.5306990881458966, 0.506079027355623, 0.4987841945288754]\n",
      "[0.4896719319562576, 0.47023086269744835, 0.51338199513382, 0.4975669099756691, 0.5121654501216545]\n",
      "[0.5043731778425656, 0.48882410106899904, 0.5286686103012633, 0.5092322643343051, 0.5063168124392614]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.5058354781203995\n",
      "0.49660342997696993\n",
      "0.5074829931972789\n"
     ]
    }
   ],
   "source": [
    "# Log Regression\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst, cnf_matrix = LogRegClassifier(table, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2466, 133)\n",
      "(823, 133)\n",
      "0.9106111280024324\n",
      "0.6452004860267315\n",
      "0.6550048590864918\n",
      "(2466, 133)\n",
      "(823, 133)\n",
      "0.9206445728184859\n",
      "0.6342648845686513\n",
      "0.6647230320699709\n",
      "(2467, 133)\n",
      "(823, 133)\n",
      "0.9145896656534954\n",
      "0.648418491484185\n",
      "0.6462585034013606\n",
      "(2467, 133)\n",
      "(823, 133)\n",
      "0.9176291793313069\n",
      "0.6520681265206812\n",
      "0.6656948493683188\n",
      "(2467, 133)\n",
      "(823, 133)\n",
      "0.9151975683890577\n",
      "0.6532846715328468\n",
      "0.652089407191448\n",
      "5 fold Train, Validation, and Test Accuracies:\n",
      "[0.9106111280024324, 0.9206445728184859, 0.9145896656534954, 0.9176291793313069, 0.9151975683890577]\n",
      "[0.6452004860267315, 0.6342648845686513, 0.648418491484185, 0.6520681265206812, 0.6532846715328468]\n",
      "[0.6550048590864918, 0.6647230320699709, 0.6462585034013606, 0.6656948493683188, 0.652089407191448]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.9157344228389557\n",
      "0.6466473320266192\n",
      "0.6567541302235179\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst, cnf_matrix = RandForestClassifier(table, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2466, 133)\n",
      "(823, 133)\n",
      "0.8528428093645485\n",
      "0.850546780072904\n",
      "0.6550048590864918\n",
      "(2466, 133)\n",
      "(823, 133)\n",
      "0.8534508969291578\n",
      "0.8481166464155528\n",
      "0.6550048590864918\n",
      "(2467, 133)\n",
      "(823, 133)\n",
      "0.8519756838905775\n",
      "0.8540145985401459\n",
      "0.6550048590864918\n",
      "(2467, 133)\n",
      "(823, 133)\n",
      "0.8516717325227964\n",
      "0.8552311435523114\n",
      "0.6550048590864918\n",
      "(2467, 133)\n",
      "(823, 133)\n",
      "0.8519756838905775\n",
      "0.8540145985401459\n",
      "0.6550048590864918\n",
      "5-fold Train, Validation, and Test Accuracies:\n",
      "[0.8528428093645485, 0.8534508969291578, 0.8519756838905775, 0.8516717325227964, 0.8519756838905775]\n",
      "[0.850546780072904, 0.8481166464155528, 0.8540145985401459, 0.8552311435523114, 0.8540145985401459]\n",
      "[0.6550048590864918, 0.6550048590864918, 0.6550048590864918, 0.6550048590864918, 0.6550048590864918]\n",
      "Avg Train, Validation, and Test Accuracies:\n",
      "0.8523833613195315\n",
      "0.8523847534242119\n",
      "0.6550048590864918\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier & Regressor\n",
    "avgsc_train_lst, avgsc_lst, avgsc_hld_lst = MLPClassifierr(table, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
